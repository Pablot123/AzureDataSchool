{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n"
     ]
    }
   ],
   "source": [
    "print('hola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\pablo.tamayo\\\\Desktop\\\\DataSchool\\\\Azure\\\\AzureDataSchool\\\\train_data.csv']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = '20d4fdf3-6a4b-4f0b-a842-bd7392136332'\n",
    "resource_group = 'cienciadatos'\n",
    "workspace_name = 'azureml'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_id(workspace, '9227d1d4-d528-48db-84ed-768975adbf63')\n",
    "dataset.download(target_path='.', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%writefile experiments/mlflow_preprocess.py\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../airlines_delay/airlines_delay.csv\", sep = \",\")\n",
    "\n",
    "def clean_data(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Delete the Fligh column\n",
    "    input: dataset\n",
    "    output: pandas dataframe withiout Flight\n",
    "    '''\n",
    "    clean_df = data.drop('Flight', axis=1, inplace=False)\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "def preprocess_data(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Preprocess the data converting the categorical columns to one hot encodig\n",
    "    and apply standarScaler to numeric columns\n",
    "    input: pandas dataFrame\n",
    "    output: tuple, first element corrempond to pd.Dataframe of independent features\n",
    "            second element is the dependent(target) feature \n",
    "    '''\n",
    "\n",
    "    numeric_columns = ['Length','Time']\n",
    "    category_columns = ['Airline', 'AirportFrom', 'AirportTo', 'DayOfWeek']\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                            ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "                        transformers=[\n",
    "                            ('numeric', numeric_transformer, numeric_columns),\n",
    "                            ('cat', categorical_transformer, category_columns)\n",
    "                        ],\n",
    "                        remainder='passthrough'\n",
    "                    )\n",
    "    \n",
    "    #split the dependent(y) and independent(df_x) features \n",
    "    df_X = data.drop('Class', axis=1, inplace=False)\n",
    "    #y_labels = data['Class']\n",
    "    y = data['Class']\n",
    "    preprocessed_data = preprocessor.fit_transform(df_X)\n",
    "    encoded_category = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(category_columns)\n",
    "\n",
    "    labels = np.concatenate([numeric_columns, encoded_category])\n",
    "    \n",
    "    preprocessed_df = pd.DataFrame(data=preprocessed_data, columns=labels)\n",
    "    return pd.concat([preprocessed_df, y], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_new = clean_data(df)\n",
    "processed_df= preprocess_data(df_new)\n",
    "processed_df.head()\n",
    "\n",
    "#df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile experiments/mlflow_eda.py\n",
    "\n",
    "from funct.myfuncs import cln_data\n",
    "import mlflow\n",
    "import argparse\n",
    "\n",
    "experiment_name ='exp-Airlines'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    \n",
    "    #loading data \n",
    "    #dataset = Dataset.get_by_name(ws, name='AirlinesDelay')\n",
    "    df = pd.read_csv(\"../airlines_delay/airlines_delay.csv\", sep = \",\")\n",
    "    \n",
    "    #Distribution of the target column\n",
    "    class_cero, class_one = df['Class'].value_counts()\n",
    "    mlflow.log_metrics({'one':class_one, 'cero':class_cero})\n",
    "    \n",
    "    #Comparation of the mean\n",
    "    mean_comparison = df[['Time','Length', 'Class']].groupby('Class').mean().to_dict()\n",
    " \n",
    "    mlflow.log_metrics({'Mean Time class cero':mean_comparison['Time'][0], 'Mean Time class one':mean_comparison['Time'][1]})\n",
    "    mlflow.log_metrics({'Mean Lenght class cero':mean_comparison['Length'][0], 'Mean Length class one':mean_comparison['Length'][1]})\n",
    "\n",
    "    #Number of airlines\n",
    "    number_of_airlines = len(df['Airline'].unique())\n",
    "\n",
    "    mlflow.log_metric('number of airlines', number_of_airlines)\n",
    "\n",
    "    #flights per airlnes\n",
    "    flights_per_airline = df['Airline'].value_counts().to_dict()\n",
    "    mlflow.log_metrics(flights_per_airline)\n",
    "\n",
    "    \n",
    "    #airports\n",
    "    number_of_airports = len(df['AirportFrom'].unique())\n",
    "    mlflow.log_metric('number of airports', number_of_airports)\n",
    "\n",
    "    #airports with more activity\n",
    "    arports_activity_df = df['AirportFrom'].value_counts().sort_values(ascending=False) + df['AirportTo'].value_counts().sort_values(ascending=False)\n",
    "    top_5_airpots_activity = arports_activity_df.sort_values(ascending=False).head(5).to_dict()\n",
    "\n",
    "    top_and_lowest_ariports_activity = {}\n",
    "    for k, _ in top_5_airpots_activity.items():\n",
    "        top_and_lowest_ariports_activity[f'Airport {k}'] = top_5_airpots_activity[k]\n",
    "\n",
    "\n",
    "    #airports with more activity\n",
    "    lowest_5_airpots_activity = arports_activity_df.sort_values(ascending=False).tail(5).to_dict()\n",
    "    for k, _ in lowest_5_airpots_activity.items():\n",
    "        top_and_lowest_ariports_activity[f'Airport {k}'] = lowest_5_airpots_activity[k]\n",
    "\n",
    "    mlflow.log_metrics(top_and_lowest_ariports_activity)\n",
    "\n",
    "    #DaysWeek\n",
    "    dict_day_of_week= {1:'Monday', 2:'Tuesday', 3:'Wednesday', 4:'Thursday', 5:'Friday', 6:'Saturday', 7: 'Sunday'}\n",
    "    df_day_of_week = df.replace({\"DayOfWeek\": dict_day_of_week},inplace=False)\n",
    "    fligths_per_day_of_week = df_day_of_week['DayOfWeek'].value_counts().to_dict()\n",
    "\n",
    "    mlflow.log_metrics(fligths_per_day_of_week)\n",
    "\n",
    "\n",
    "    #plot distribution of time\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = fig.gca()    \n",
    "    plt.hist(df['Length'])\n",
    "    plt.show()\n",
    "    mlflow.log_figure(fig, \"plot.png\")\n",
    "    print(\"Plot listo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_data.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "\n",
    "x = df.drop('Class', axis=1, inplace=False)\n",
    "y = df['Class']\n",
    "\n",
    "'''\n",
    "lr_cv = cross_validate(LogisticRegression(max_iter=400), x, y, cv=2, scoring=['balanced_accuracy', 'recall', 'precision'], return_train_score=True)\n",
    "print('Listo regresion lineal')\n",
    "#rf_cv = cross_validate(RandomForestClassifier(), x, y, cv=3, scoring=['balanced_accuracy', 'recall', 'precision'], return_train_score=True)\n",
    "#print('Listo random forest')\n",
    "svm = cross_validate(SVC(), x, y, cv = 3, scoring=['balanced_accuracy', 'recall', 'precision'], return_train_score=True)\n",
    "print('Listo SVM')\n",
    "\n",
    "hola =[]\n",
    "for score_model, name_model in [(lr_cv, 'lr'), (svm, 'svm')]:\n",
    "    hola.append({\n",
    "        f'train_acc_{name_model}': np.mean(score_model['train_balanced_accuracy']),\n",
    "        f'train_recall_{name_model}': np.mean(score_model['train_recall']),\n",
    "        f'train_precision_{name_model}': np.mean(score_model['train_precision']),\n",
    "        f'test_acc_{name_model}': np.mean(score_model['test_balanced_accuracy']),\n",
    "        f'test_recall_{name_model}': np.mean(score_model['test_recall']),\n",
    "        f'test_precision_{name_model}': np.mean(score_model['test_precision'])\n",
    "    })\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "param_dist ={\n",
    "    'penalty':['l1', 'l2', 'elasticnet'],\n",
    "    'C': [c/10 for c in range(1,20,5)],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "\n",
    "}\n",
    "clf = RandomizedSearchCV(LogisticRegression(), param_dist, n_iter=5, random_state=0, refit='balanced_accuracy')\n",
    "'''\n",
    "mlflow.log_params({\n",
    "    'penalty': 'l2',\n",
    "    'C': 1.0,\n",
    "    'solver':'lbfgs'\n",
    "})\n",
    "'''\n",
    "clf.fit(x,y)\n",
    "\n",
    "#mlflow.sklearn.log_model(lr, artifact_path='skleran-model')\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "recall = recall_score(y,y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "acc = accuracy_score(y, y_pred)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "print(recall)\n",
    "print(precision)\n",
    "print(acc)\n",
    "print(conf_matrix)\n",
    "\n",
    "#logging.info(f'matriz de confusion{conf_matrix}')\n",
    "\n",
    "'''\n",
    "mlflow.log_metrics({\n",
    "    'recall':recall,\n",
    "    'precision': precision,\n",
    "    'accuracy': acc,\n",
    "\n",
    "})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'newton-cg', 'penalty': 'l2', 'C': 0.6}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msvm\u001b[39;00m \u001b[39mimport\u001b[39;00m SVC\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "\n",
    "x = df.drop('Class', axis=1, inplace=False)\n",
    "y = df['Class']\n",
    "\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "svm.fit(x,y)\n",
    "\n",
    "y_pred = svm.predict(x)\n",
    "\n",
    "recall = recall_score(y,y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "acc = accuracy_score(y, y_pred)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "print(recall)\n",
    "print(precision)\n",
    "print(acc)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from azureml.core import Workspace, Datastore, Run, Dataset\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from src.utils import dataset_transform\n",
    "import argparse\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "#run = Run.get_context()\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "#raw_data_test = run.input_datasets['raw_test_data'].to_pandas_dataframe()\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    #load the latest version of the model\n",
    "    model_name = 'airlines_model'\n",
    "    model = mlflow.sklearn.load_model(f'models:/{model_name}/latest')\n",
    "    print('loaded model')\n",
    "    #mlflow.log_metric('prueba',1)\n",
    "    dataset = Dataset.get_by_name(ws, name='airlines_train_data')\n",
    "    df_all = dataset.to_pandas_dataframe()\n",
    "\n",
    "#pred = model.predict(transformed_data_test.drop('Class', axis=1, inplace=False))\n",
    "\n",
    "#acc = balanced_accuracy_score(transformed_data_test['Class'], pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Airline</th>\n",
       "      <th>AirportFrom</th>\n",
       "      <th>AirportTo</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>825.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1155.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHL</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>965.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>WN</td>\n",
       "      <td>SJC</td>\n",
       "      <td>ONT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>WN</td>\n",
       "      <td>SJC</td>\n",
       "      <td>PDX</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>525.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time  Length Airline AirportFrom AirportTo  DayOfWeek  Class\n",
       "0   825.0   160.0      AA         DFW       DCA          1      1\n",
       "1  1155.0   130.0      DL         ATL       PHL          4      0\n",
       "2   965.0    70.0      WN         SJC       ONT          1      1\n",
       "3   800.0   105.0      WN         SJC       PDX          5      1\n",
       "4   525.0   105.0      AA         DFW       OMA          6      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "def dataset_transform_prueba(train_df=pd.DataFrame([]), val_df=pd.DataFrame([]), test_df=pd.DataFrame([])):\n",
    "\n",
    "    numeric_columns = ['Length','Time']\n",
    "    category_columns = ['Airline', 'AirportFrom', 'AirportTo', 'DayOfWeek']\n",
    "    \n",
    "    oh_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    if (not(train_df.empty) and not(val_df.empty) and test_df.empty):\n",
    "        \n",
    "        #transforming train data\n",
    "        X_train = train_df.drop('Class', axis=1, inplace=False)\n",
    "        y_train = train_df['Class']\n",
    "\n",
    "        X_train_oh = oh_encoder.fit_transform(X_train[category_columns])\n",
    "        X_train_sc = sc.fit_transform(X_train[numeric_columns])\n",
    "        one_hot_columns_name = oh_encoder.get_feature_names_out()\n",
    "\n",
    "        train_oh_df = pd.DataFrame(data = X_train_oh, columns = one_hot_columns_name)\n",
    "        train_sc_df = pd.DataFrame(data = X_train_sc, columns=numeric_columns)\n",
    "\n",
    "        train_df = pd.concat([train_sc_df, train_oh_df, y_train], axis=1)\n",
    "\n",
    "        #transformig val data\n",
    "        X_val = val_df.drop('Class', axis=1, inplace=False)\n",
    "        y_val = val_df['Class']\n",
    "\n",
    "        X_val_oh = oh_encoder.transform(X_val[category_columns])\n",
    "        X_val_sc = sc.transform(X_val[numeric_columns])\n",
    "        one_hot_columns_name = oh_encoder.get_feature_names_out()\n",
    "\n",
    "        val_oh_df = pd.DataFrame(data = X_val_oh, columns = one_hot_columns_name)\n",
    "        val_sc_df = pd.DataFrame(data = X_val_sc, columns=numeric_columns)\n",
    "\n",
    "        val_df = pd.concat([val_sc_df, val_oh_df, y_val], axis=1)\n",
    "\n",
    "\n",
    "        #save the encoder and scaler\n",
    "        joblib.dump(oh_encoder, 'oh_encoder.joblib')\n",
    "        joblib.dump(sc, 'standarScaler.joblib')\n",
    "\n",
    "\n",
    "        return train_df, val_df\n",
    "    \n",
    "    elif (train_df.empty and val_df.empty and not(test_df.empty)):\n",
    "        test_df.reset_index(inplace=True)\n",
    "        \n",
    "        X_test= test_df.drop('Class', axis=1, inplace=False)\n",
    "        y_test = test_df['Class']\n",
    "\n",
    "        runs = mlflow.search_runs(experiment_names=[\"exp-Airlines\"])\n",
    "        recent_run = runs[['run_id', 'end_time' ]].loc[(runs['tags.mlflow.source.name'] == 'scripts/data_transform.py') & (runs['status'] == 'FINISHED')].sort_values(by='end_time', ascending=False).head(1)\n",
    "        recent_run_id = recent_run['run_id'].to_string().split()[1]\n",
    "\n",
    "        a = mlflow.artifacts.download_artifacts(run_id=recent_run_id, artifact_path='oh_encoder.joblib')\n",
    "        b = mlflow.artifacts.download_artifacts(run_id=recent_run_id, artifact_path='standarScaler.joblib')\n",
    "\n",
    "      \n",
    "        sc_t = joblib.load(b)\n",
    "        oh_t = joblib.load(a)\n",
    "\n",
    "        sc_data_test = sc_t.transform(X_test[numeric_columns])\n",
    "        oh_data_test = oh_t.transform(X_test[category_columns])\n",
    "        one_hot_columns_name_test = oh_t.get_feature_names_out()\n",
    "\n",
    "        test_oh_df = pd.DataFrame(data = oh_data_test, columns = one_hot_columns_name_test)\n",
    "        test_sc_df = pd.DataFrame(data = sc_data_test, columns=numeric_columns)\n",
    "\n",
    "        test_df_p = pd.concat([test_sc_df, test_oh_df, y_test], axis=1)\n",
    "\n",
    "        return test_df_p\n",
    "    \n",
    "    else:\n",
    "        return 'Worng combination'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,c = dataset_transform_prueba(train_df=df_all, val_df=df_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Time</th>\n",
       "      <th>Airline_DL</th>\n",
       "      <th>Airline_MQ</th>\n",
       "      <th>Airline_OO</th>\n",
       "      <th>Airline_WN</th>\n",
       "      <th>AirportFrom_ABI</th>\n",
       "      <th>AirportFrom_ABQ</th>\n",
       "      <th>AirportFrom_ACT</th>\n",
       "      <th>AirportFrom_ACV</th>\n",
       "      <th>...</th>\n",
       "      <th>AirportTo_VPS</th>\n",
       "      <th>AirportTo_XNA</th>\n",
       "      <th>AirportTo_YUM</th>\n",
       "      <th>DayOfWeek_2</th>\n",
       "      <th>DayOfWeek_3</th>\n",
       "      <th>DayOfWeek_4</th>\n",
       "      <th>DayOfWeek_5</th>\n",
       "      <th>DayOfWeek_6</th>\n",
       "      <th>DayOfWeek_7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.468432</td>\n",
       "      <td>0.083172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018404</td>\n",
       "      <td>1.287022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.881652</td>\n",
       "      <td>0.593896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.356620</td>\n",
       "      <td>-0.008029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.356620</td>\n",
       "      <td>-1.011238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Length      Time  Airline_DL  Airline_MQ  Airline_OO  Airline_WN  \\\n",
       "0  0.468432  0.083172         0.0         0.0         0.0         0.0   \n",
       "1  0.018404  1.287022         1.0         0.0         0.0         0.0   \n",
       "2 -0.881652  0.593896         0.0         0.0         0.0         1.0   \n",
       "3 -0.356620 -0.008029         0.0         0.0         0.0         1.0   \n",
       "4 -0.356620 -1.011238         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   AirportFrom_ABI  AirportFrom_ABQ  AirportFrom_ACT  AirportFrom_ACV  ...  \\\n",
       "0              0.0              0.0              0.0              0.0  ...   \n",
       "1              0.0              0.0              0.0              0.0  ...   \n",
       "2              0.0              0.0              0.0              0.0  ...   \n",
       "3              0.0              0.0              0.0              0.0  ...   \n",
       "4              0.0              0.0              0.0              0.0  ...   \n",
       "\n",
       "   AirportTo_VPS  AirportTo_XNA  AirportTo_YUM  DayOfWeek_2  DayOfWeek_3  \\\n",
       "0            0.0            0.0            0.0          0.0          0.0   \n",
       "1            0.0            0.0            0.0          0.0          0.0   \n",
       "2            0.0            0.0            0.0          0.0          0.0   \n",
       "3            0.0            0.0            0.0          0.0          0.0   \n",
       "4            0.0            0.0            0.0          0.0          0.0   \n",
       "\n",
       "   DayOfWeek_4  DayOfWeek_5  DayOfWeek_6  DayOfWeek_7  Class  \n",
       "0          0.0          0.0          0.0          0.0      1  \n",
       "1          1.0          0.0          0.0          0.0      0  \n",
       "2          0.0          0.0          0.0          0.0      1  \n",
       "3          0.0          1.0          0.0          0.0      1  \n",
       "4          0.0          0.0          1.0          0.0      0  \n",
       "\n",
       "[5 rows x 489 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "917980f1-9e6a-4eba-8da8-dca7161e96af\n",
      "345    \n",
      "Name: artifact_uri, dtype: object\n"
     ]
    }
   ],
   "source": [
    "t = dataset_transform_prueba(test_df=df_all[40:41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Time</th>\n",
       "      <th>Airline_DL</th>\n",
       "      <th>Airline_MQ</th>\n",
       "      <th>Airline_OO</th>\n",
       "      <th>Airline_WN</th>\n",
       "      <th>AirportFrom_ABI</th>\n",
       "      <th>AirportFrom_ABQ</th>\n",
       "      <th>AirportFrom_ACT</th>\n",
       "      <th>AirportFrom_ACV</th>\n",
       "      <th>...</th>\n",
       "      <th>AirportTo_VPS</th>\n",
       "      <th>AirportTo_XNA</th>\n",
       "      <th>AirportTo_YUM</th>\n",
       "      <th>DayOfWeek_2</th>\n",
       "      <th>DayOfWeek_3</th>\n",
       "      <th>DayOfWeek_4</th>\n",
       "      <th>DayOfWeek_5</th>\n",
       "      <th>DayOfWeek_6</th>\n",
       "      <th>DayOfWeek_7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.881652</td>\n",
       "      <td>0.028451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Length      Time  Airline_DL  Airline_MQ  Airline_OO  Airline_WN  \\\n",
       "0 -0.881652  0.028451         1.0         0.0         0.0         0.0   \n",
       "\n",
       "   AirportFrom_ABI  AirportFrom_ABQ  AirportFrom_ACT  AirportFrom_ACV  ...  \\\n",
       "0              0.0              0.0              0.0              0.0  ...   \n",
       "\n",
       "   AirportTo_VPS  AirportTo_XNA  AirportTo_YUM  DayOfWeek_2  DayOfWeek_3  \\\n",
       "0            0.0            0.0            0.0          0.0          1.0   \n",
       "\n",
       "   DayOfWeek_4  DayOfWeek_5  DayOfWeek_6  DayOfWeek_7  Class  \n",
       "0          0.0          0.0          0.0          0.0      0  \n",
       "\n",
       "[1 rows x 489 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(\n",
    "        experiment_names=[\"exp-Airlines\"]\n",
    "    )\n",
    "runs.to_csv('runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_run = runs[['run_id', 'end_time' ]].loc[(runs['tags.mlflow.source.name'] == 'scripts/data_transform.py') & (runs['status'] == 'FINISHED')].sort_values(by='end_time', ascending=False).head(1)\n",
    "recent_run_id = recent_run['run_id'].to_string().split()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'917980f1-9e6a-4eba-8da8-dca7161e96af'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_file_names() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[219], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hola \u001b[39m=\u001b[39m Run\u001b[39m.\u001b[39;49mget_file_names()\n",
      "\u001b[1;31mTypeError\u001b[0m: get_file_names() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "hola = Run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\PABLO~1.TAM\\\\AppData\\\\Local\\\\Temp\\\\tmpsgg_o2hr\\\\oh_encoder.joblib'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
