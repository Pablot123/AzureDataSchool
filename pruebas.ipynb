{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\pablo.tamayo\\\\Desktop\\\\DataSchool\\\\Azure\\\\AzureDataSchool\\\\train_data.csv']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = '20d4fdf3-6a4b-4f0b-a842-bd7392136332'\n",
    "resource_group = 'cienciadatos'\n",
    "workspace_name = 'azureml'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_id(workspace, '9227d1d4-d528-48db-84ed-768975adbf63')\n",
    "dataset.download(target_path='.', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_data.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pablo.tamayo\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 25.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablo.tamayo\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\pablo.tamayo\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\pablo.tamayo\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablo.tamayo\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\pablo.tamayo\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\pablo.tamayo\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\pablo.tamayo\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.64336093 0.64336093        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6371029795237891\n",
      "0.6562854343494391\n",
      "0.6458278994957398\n",
      "[[59238 31222]\n",
      " [33957 59615]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmlflow.log_metrics({\\n    'recall':recall,\\n    'precision': precision,\\n    'accuracy': acc,\\n\\n})\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "\n",
    "x = df.drop('Class', axis=1, inplace=False)\n",
    "y = df['Class']\n",
    "\n",
    "'''\n",
    "lr_cv = cross_validate(LogisticRegression(max_iter=400), x, y, cv=2, scoring=['balanced_accuracy', 'recall', 'precision'], return_train_score=True)\n",
    "print('Listo regresion lineal')\n",
    "#rf_cv = cross_validate(RandomForestClassifier(), x, y, cv=3, scoring=['balanced_accuracy', 'recall', 'precision'], return_train_score=True)\n",
    "#print('Listo random forest')\n",
    "svm = cross_validate(SVC(), x, y, cv = 3, scoring=['balanced_accuracy', 'recall', 'precision'], return_train_score=True)\n",
    "print('Listo SVM')\n",
    "\n",
    "hola =[]\n",
    "for score_model, name_model in [(lr_cv, 'lr'), (svm, 'svm')]:\n",
    "    hola.append({\n",
    "        f'train_acc_{name_model}': np.mean(score_model['train_balanced_accuracy']),\n",
    "        f'train_recall_{name_model}': np.mean(score_model['train_recall']),\n",
    "        f'train_precision_{name_model}': np.mean(score_model['train_precision']),\n",
    "        f'test_acc_{name_model}': np.mean(score_model['test_balanced_accuracy']),\n",
    "        f'test_recall_{name_model}': np.mean(score_model['test_recall']),\n",
    "        f'test_precision_{name_model}': np.mean(score_model['test_precision'])\n",
    "    })\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "param_dist ={\n",
    "    'penalty':['l1', 'l2', 'elasticnet'],\n",
    "    'C': [c/10 for c in range(1,20,5)],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "\n",
    "}\n",
    "clf = RandomizedSearchCV(LogisticRegression(), param_dist, n_iter=5, random_state=0, refit='balanced_accuracy')\n",
    "'''\n",
    "mlflow.log_params({\n",
    "    'penalty': 'l2',\n",
    "    'C': 1.0,\n",
    "    'solver':'lbfgs'\n",
    "})\n",
    "'''\n",
    "clf.fit(x,y)\n",
    "\n",
    "#mlflow.sklearn.log_model(lr, artifact_path='skleran-model')\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "recall = recall_score(y,y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "acc = accuracy_score(y, y_pred)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "print(recall)\n",
    "print(precision)\n",
    "print(acc)\n",
    "print(conf_matrix)\n",
    "\n",
    "#logging.info(f'matriz de confusion{conf_matrix}')\n",
    "\n",
    "'''\n",
    "mlflow.log_metrics({\n",
    "    'recall':recall,\n",
    "    'precision': precision,\n",
    "    'accuracy': acc,\n",
    "\n",
    "})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'newton-cg', 'penalty': 'l2', 'C': 0.6}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
